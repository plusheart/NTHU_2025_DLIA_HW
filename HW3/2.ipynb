{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Li0bVCTuxc6n"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "#### Lab 3\n",
    "\n",
    "# National Tsing Hua University\n",
    "\n",
    "#### Spring 2025\n",
    "\n",
    "#### 11320IEEM 513600\n",
    "\n",
    "#### Deep Learning and Industrial Applications\n",
    "    \n",
    "## Lab 3: Anomaly Detection in Industrial Applications\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlvflhYwCu8Q"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "In today's industrial landscape, the ability to detect anomalies in manufacturing processes and products is critical for maintaining quality, efficiency, and safety. This lab focuses on leveraging deep learning techniques for anomaly detection in various industrial applications, using the MVTEC Anomaly Detection Dataset. By employing ImageNet-pretrained models available in torchvision, students will gain hands-on experience in classfying defects and irregularities across different types of industrial products.\n",
    "\n",
    "Throughout this lab, you'll be involved in the following key activities:\n",
    "- Explore and process the MVTec Anomaly Detection Dataset.\n",
    "- Apply ImageNet-pretrained models from [Torchvision](https://pytorch.org/vision/stable/models.html) to detect anomalies in industrial products.\n",
    "- Evaluate the performance of the models to understand their effectiveness in real-world industrial applications.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Understand the principles of anomaly detection in the context of industrial applications.\n",
    "- Learn how to implement and utilize ImageNet-pretrained models for detecting anomalies.\n",
    "- Analyze and interpret the results of the anomaly detection models to assess their practicality in industrial settings.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The MVTec AD Dataset is a comprehensive collection of high-resolution images across different categories of industrial products, such as bottles, cables, and metal nuts, each with various types of defects. This dataset is pivotal for developing and benchmarking anomaly detection algorithms. You can download our lab's dataset [here](https://drive.google.com/file/d/19600hUOpx0hl78TdpdH0oyy-gGTk_F_o/view?usp=share_link). You can drop downloaded data and drop to colab, or you can put into yor google drive.\n",
    "\n",
    "### References\n",
    "- [MVTec AD Dataset](https://www.kaggle.com/datasets/ipythonx/mvtec-ad/data) for the dataset used in this lab.\n",
    "- [Torchvision Models](https://pytorch.org/vision/stable/models.html) for accessing ImageNet-pretrained models to be used in anomaly detection tasks.\n",
    "- [State-of-the-Art Anomaly Detection on MVTec AD](https://paperswithcode.com/sota/anomaly-detection-on-mvtec-ad) for insights into the latest benchmarks and methodologies in anomaly detection applied to the MVTec AD dataset.\n",
    "- [CVPR 2019: MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection] for the original paper of MVTec AD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuiEw1L0Cu8Q"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qvLTTCGsCu8R",
    "outputId": "8163caec-f7d4-4ca0-dc52-42f98bafbbff"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 解壓縮 cable 資料集\n",
    "#!tar -xvf drive/MyDrive/cable.tar.gz zipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKsJWULFs-HD",
    "outputId": "65548b5d-cc9d-491f-a2c4-dd81cb8e138e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "subdir = \"/content/drive/MyDrive/DeepLearning/hw3/MVTec AD Dataset/\"\n",
    "print(os.listdir(subdir))  # 列出 cable 目錄下的所有檔案與資料夾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yXfjTWKUCu8R",
    "outputId": "f6d4407d-dde4-4183-d1c0-0bbf566ef48d"
   },
   "outputs": [],
   "source": [
    "file_paths = glob.glob('/content/drive/MyDrive/DeepLearning/hw3/MVTec AD Dataset/bottle/*/*/*.png')\n",
    "file_paths = sorted([path for path in file_paths if path.split('/')[-1] in [f'{i:03}.png' for i in range(10)]])\n",
    "\n",
    "print(f\"Found {len(file_paths)} images\")\n",
    "print(file_paths[:5])  # 顯示前 5 個檔案路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "671b610343774a35b2fc55b07bfc6ed3",
      "66ce5ce00aac499fa1a2dd1498ecc637",
      "c3f6bdb1af4247458494c109c6f61333",
      "e266b4b7e5f44245a05d22dc26aa6dd9",
      "07b4bb1dacbd4197b7e623ea3e83a361",
      "fc8b7261acb4420ab6112572a611ca07",
      "6ceaab41d10244b890c35ff4963a5caf",
      "1b1948df1e86482e851c64746cf8d35a",
      "be45a177757a41d5ab1379439c84f2fa",
      "be84e2dc49e64a7bb2728b3fd238c785",
      "c495ab5e0abd45e7956f7793b592c96c"
     ]
    },
    "id": "3GiOZBRJCu8S",
    "outputId": "303ae5d9-1316-4fb5-993d-c64c503517f8"
   },
   "outputs": [],
   "source": [
    "# 讀取圖片資料\n",
    "all_data = []\n",
    "\n",
    "for img in tqdm(file_paths):  # tqdm 用於顯示進度條\n",
    "    img = cv2.imread(img)  # 使用 OpenCV 讀取圖片 (Blue-Green-Red)\n",
    "    img = img[..., ::-1]  # 將 BGR 轉為 RGB（Red-Green-Blue）>>for 深度學習模型\n",
    "    all_data.append(img)\n",
    "\n",
    "all_data = np.stack(all_data) # 將 list 轉為 numpy array>>效率高、支援向量化運算\n",
    "# PyTorch、TensorFlow 等框架中也傾向直接處理 array 格式的資料\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ii8LH8s4Cu8S",
    "outputId": "2d23ff74-f4ab-4edd-de88-2fe4cae9ad25"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#classes = sorted(set([path.split('/')[1] for path in file_paths]))\n",
    "classes = sorted(set([path.split('/')[-2] for path in file_paths]))\n",
    "print(f'Classes: {classes}')\n",
    "\n",
    "images_per_class = len(all_data) // len(classes)\n",
    "\n",
    "# 畫出每個類別的前兩張圖片做視覺化\n",
    "fig, axs = plt.subplots(len(classes), 2, figsize=(6, 4 * len(classes)))\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    index = i * images_per_class\n",
    "    for j in range(2):\n",
    "        axs[i, j].set_title(f'{i}. {class_name}')\n",
    "        axs[i, j].imshow(all_data[index + j])\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 總共八類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkfmyuuJA_7d",
    "outputId": "7a549415-3512-407d-e28a-2b66f471f687"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# 統計 file_paths 中每個類別的圖片數量\n",
    "class_counts = Counter([path.split('/')[-2] for path in file_paths])\n",
    "print(\"原始資料集中各類別的圖片數量:\")\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\" - {cls}: {count} 張\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "nicku_gNBJBt",
    "outputId": "0a98db2f-eea7-4ea8-d0f0-d73a01e937b7"
   },
   "outputs": [],
   "source": [
    "# 用條狀圖畫出來\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n",
    "plt.title(\"type of defect\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Image Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-1PsC--M7pT"
   },
   "source": [
    "## A. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGFI8GMpCu8S",
    "outputId": "a0977335-682c-4385-c604-9ea7f03243a0"
   },
   "outputs": [],
   "source": [
    "# 將資料分成訓練集與驗證集\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "\n",
    "num_classes = 4\n",
    "images_per_class = 10\n",
    "train_images_per_class = int(images_per_class * 0.8)\n",
    "val_images_per_class = int(images_per_class * 0.2)\n",
    "\n",
    "x_train = []\n",
    "x_val = []\n",
    "\n",
    "# 將每個類別的圖片依比例加入訓練與驗證集\n",
    "for i in range(num_classes):\n",
    "    start_index = i * images_per_class\n",
    "    x_train.extend(all_data[start_index:start_index + train_images_per_class])\n",
    "    x_val.extend(all_data[start_index + train_images_per_class:start_index + images_per_class])\n",
    "\n",
    "# 轉換資料格式為 PyTorch 需要的格式：(batch, channel, height, width)\n",
    "x_train = np.transpose(np.array(x_train), (0, 3, 1, 2))\n",
    "x_val = np.transpose(np.array(x_val), (0, 3, 1, 2))\n",
    "\n",
    "# 建立對應的標籤\n",
    "y_train = np.concatenate([np.full(train_images_per_class, i) for i in range(num_classes)])\n",
    "y_val = np.concatenate([np.full(val_images_per_class, i) for i in range(num_classes)])\n",
    "\n",
    "print(f'Shape of x_train: {x_train.shape}')\n",
    "print(f'Shape of x_val: {x_val.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_val: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "id": "_uXGzam0BMIb",
    "outputId": "e7eb5237-738a-4a99-83e4-3e69f8862dcf"
   },
   "outputs": [],
   "source": [
    "# 建立對應的標籤名稱\n",
    "class_names = sorted(set([path.split('/')[-2] for path in file_paths]))\n",
    "\n",
    "# 轉成 pandas DataFrame 做分析\n",
    "train_df = pd.DataFrame({'label': y_train})\n",
    "val_df = pd.DataFrame({'label': y_val})\n",
    "\n",
    "# 訓練集分布\n",
    "train_counts = train_df['label'].value_counts().sort_index()\n",
    "val_counts = val_df['label'].value_counts().sort_index()\n",
    "\n",
    "# 顯示統計資料\n",
    "print(\"\\n[Train Set dis.]\")\n",
    "for idx, count in enumerate(train_counts):\n",
    "    print(f\"{class_names[idx]}: {count} 張\")\n",
    "\n",
    "print(\"\\n[Validation Set dis.]\")\n",
    "for idx, count in enumerate(val_counts):\n",
    "    print(f\"{class_names[idx]}: {count} 張\")\n",
    "\n",
    "# 視覺化分布\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axs[0].bar(class_names, train_counts, color='lightgreen')\n",
    "axs[0].set_title(\"Train Set dis.\")\n",
    "axs[0].set_xlabel(\"Class\")\n",
    "axs[0].set_ylabel(\"Count\")\n",
    "axs[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axs[1].bar(class_names, val_counts, color='salmon')\n",
    "axs[1].set_title(\"Validation Set dis.\")\n",
    "axs[1].set_xlabel(\"Class\")\n",
    "axs[1].set_ylabel(\"Count\")\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-CnfsmbCu8T"
   },
   "outputs": [],
   "source": [
    "# 定義影像增強與轉換方法\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "# 訓練集轉換：包含資料增強\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# 驗證集轉換：只做 Resize 與 ToTensor\n",
    "# 驗證集不能做隨機增強，否則每次驗證結果不一致，無法公平比較模型的準確率\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 自定義 Dataset 類別\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        self.x = x\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        new_x = np.transpose(self.x[idx], (1, 2, 0))\n",
    "        return self.transform(Image.fromarray(new_x)), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53ZVFFacCu8T"
   },
   "outputs": [],
   "source": [
    "# 建立資料加載器\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = MyDataset(x_train, y_train, train_transform)\n",
    "val_dataset = MyDataset(x_val, y_val, val_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, persistent_workers=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaLGtT28xc6s"
   },
   "source": [
    "## B. Defining Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDX8iDKJCu8U",
    "outputId": "ef0cabb3-ed74-4623-a30a-6e290dff1266"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# 加載預訓練的 ResNet 模型\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# 預設先凍結所有層\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 解凍最後的分類層（'fc' 層）\n",
    "model.fc.requires_grad = True\n",
    "\n",
    "# 凍結所有層參數（僅微調最後一層）\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "num_class = 4\n",
    "\n",
    "# 替換輸出層為我們的分類數量（原本是1000類，現在改為8類）\n",
    "model.fc = nn.Linear(num_ftrs, num_class)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvLTU-IfZLqn"
   },
   "source": [
    "## C. Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917,
     "referenced_widgets": [
      "ca3bff13d93f4a599fffdba35570dddf",
      "b3844dad0de343d197a04a6f10a8e142",
      "62e08199b0ed4cee8759002d47ecddd5",
      "54f55db435e142c183994f5b3743a3bc",
      "7709256383b548cca92838fdb60f3fbe",
      "544e11fb806d43e792f47d758b53db1b",
      "94c26b058d3048d4b4e0870d82fed194",
      "e89382d74c3c4cd7b58e543018852999",
      "7a5af0abd51d4ca7965d7d4dc4d46630",
      "5a0092059ff94f7aa53093643218ac85",
      "847aee55ce0f47278dbf250e3ee12b84"
     ]
    },
    "id": "45ol4lpVxc6t",
    "outputId": "57b566a4-0346-4f7d-86c7-e58995e0bc6b"
   },
   "outputs": [],
   "source": [
    "# 設定訓練相關的超參數\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "epochs = 50\n",
    "model = model.cuda()\n",
    "\n",
    "# 儲存最佳模型的參數\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = -1\n",
    "\n",
    "# 定義 loss、optimizer、學習率調整器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader)*epochs, eta_min=0)\n",
    "\n",
    "# 開始訓練模型\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # -------- Training --------\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.cuda()\n",
    "        images = (images) / 255.\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        labels = labels.long()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        train_predicted = outputs.argmax(-1)\n",
    "        train_correct += (train_predicted == labels).sum().item()\n",
    "        total_train_samples += labels.size(0)\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = 100. * train_correct / total_train_samples\n",
    "\n",
    "    # -------- Validation --------\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.cuda()\n",
    "            images = (images) / 255.\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(images)\n",
    "\n",
    "            labels = labels.long()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            predicted = outputs.argmax(-1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = 100. * correct / total\n",
    "\n",
    "    # 更新學習率\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # 儲存最佳模型\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        torch.save(model.state_dict(), 'model_classification.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train loss: {avg_train_loss:.4f}, Train acc: {train_accuracy:.4f}%, Val loss: {avg_val_loss:.4f}, Val acc: {val_accuracy:.4f}%, Best Val loss: {best_val_loss:.4f} Best Val acc: {best_val_acc:.2f}%')\n",
    "\n",
    "    # 儲存訓練過程數據\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjmYxAJnxc6t"
   },
   "source": [
    "### Visualizing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "pHpS0Q7vxc6t",
    "outputId": "a6045230-da1e-479e-c748-5f49bfba9aaa"
   },
   "outputs": [],
   "source": [
    "# 畫出訓練過程的準確率與損失變化\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "ax[0].plot(train_accuracies)\n",
    "ax[0].plot(val_accuracies)\n",
    "ax[0].set_title('Model Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(['Train', 'Val'])\n",
    "\n",
    "# Plotting training and validation loss\n",
    "ax[1].plot(train_losses)\n",
    "ax[1].plot(val_losses)\n",
    "ax[1].set_title('Model Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend(['Train', 'Val'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVDWBwv6Cu8V"
   },
   "source": [
    "## D. Evaluating Your Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEztHBDjCu8V"
   },
   "source": [
    "### Load Trained Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DA1qHXpCu8V",
    "outputId": "789360da-3c39-4416-9faf-e6816ab45f5f"
   },
   "outputs": [],
   "source": [
    "# 測試最終模型效能\n",
    "# 載入最佳模型參數\n",
    "model.load_state_dict(torch.load('model_classification.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "\n",
    "        images = images.cuda()\n",
    "        images = (images) / 255.\n",
    "\n",
    "        labels = labels.cuda()\n",
    "        labels = labels.long()\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        predicted = outputs.argmax(-1)\n",
    "        print(predicted)\n",
    "        print(labels) # 真實標籤\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "print(f'Test accuracy is {100. * test_correct / test_total}%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
