{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "609dcb62-c2f8-4c6d-9c89-63dc0148a87c"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "### Lab 4\n",
    "\n",
    "# National Tsing Hua University\n",
    "\n",
    "#### Spring 2025\n",
    "\n",
    "#### 11320IEEM 513600\n",
    "\n",
    "#### Deep Learning and Industrial Applications\n",
    "    \n",
    "## Lab 4: Predicting Stock Price with Deep Learning\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "061c22d2-eec4-40f4-866b-ccaa2d9a2963",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Introduction\n",
    "\n",
    "In this lab, we explore the application of time-series datasets using Long Short-Term Memory (LSTM) networks, a type of recurrent neural network, to predict stock prices. Specifically, we will use historical price data from Nvidia to forecast the stock's price for the next day based on the prices of the previous N days. This approach is particularly relevant given the volatile nature of stock markets and the increasing reliance on automated trading systems.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- To understand the fundamentals of LSTM networks and their application in time-series forecasting.\n",
    "- To develop a predictive model that can accurately forecast Nvidia's stock price for the next day using historical data.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset for this lab is from the \"Huge Stock Market Dataset\" available on Kaggle. This dataset includes daily prices and volumes for all US stocks and ETFs, with a specific focus on Nvidia (NVDA). The dataset features include:\n",
    "\n",
    "- **Date**: The recorded data points.\n",
    "- **Open**: The price at which the stock first traded upon the opening of an exchange on a given trading day.\n",
    "- **High**: The highest price at which the stock traded during the trading day.\n",
    "- **Low**: The lowest price at which the stock traded during the trading day.\n",
    "- **Close**: The price of the stock at closing time.\n",
    "- **Volume**: The number of shares or contracts traded in a security or an entire market during a given period.\n",
    "- **OpenInt**: The total number of outstanding derivative contracts, like options or futures. [More details here](https://www.kaggle.com/datasets/borismarjanovic/price-volume-data-for-all-us-stocks-etfs/discussion/121096)\n",
    "\n",
    "### References\n",
    "\n",
    "- [Huge Stock Market Dataset](https://www.kaggle.com/datasets/borismarjanovic/price-volume-data-for-all-us-stocks-etfs) for the dataset used in this lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "ytUZU90IvWn9"
   },
   "source": [
    "訓練一個 LSTM 模型來預測 NVIDIA 股票的隔日最高價（High）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "ad594fc8-4989-40f3-b124-4550fe7df386"
   },
   "source": [
    "## A. Checking and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QN9wm55dAwyz",
    "outputId": "65d9864f-9d3f-43f8-ad8f-7f2e0807c233"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "42a3eafd-cbcd-4c56-82cb-83a0bfa2399e",
    "outputId": "dbd1bd00-658b-4631-915a-066932dc377f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/content/drive/MyDrive/DeepLearning/hw4/nvda.us.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "97f3e5ca-600c-42f6-88d2-8e057ca2c612",
    "outputId": "b8e7be02-fc85-469b-9423-52c789b65bb5"
   },
   "outputs": [],
   "source": [
    "# 繪製 High（每日最高價）折線圖作為初步觀察\n",
    "plot = df.plot('Date', 'High', figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34241797-60f0-4818-a44b-f5379948d621",
    "outputId": "14b489db-658b-4af0-e1cf-4eeb260fae67"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "026585db-a6d8-4062-85de-e3a7eaebed72",
    "outputId": "0d5f20d9-b7b2-4a4d-f4b2-eaf40e3d62b8"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "69031e6d-0fb5-49d9-b723-a0d1fee08c3c",
    "outputId": "7a826f76-0037-4b70-a694-873c2d95ce34"
   },
   "outputs": [],
   "source": [
    "# checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "cb3090f8-2cfa-4f56-8aa5-cf954bb19932"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38aadbee-d68f-4ae0-b842-b40800b0cac9",
    "outputId": "055ba11a-374d-436c-a84f-2c223655a9f0"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "051108c6-7011-4187-9e36-bd2944a019ca",
    "outputId": "c8e7344e-000e-4a16-8512-05119a2c32d3"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "8ce7a0c5-76d6-4863-ba61-0544a220962a"
   },
   "source": [
    "#### Converting the DataFrame to a NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "5735baad-2db8-4306-aa4c-7788d2b49621"
   },
   "outputs": [],
   "source": [
    "# 將資料轉成時間序列格式，window size 為 10，step 為 15\n",
    "def create_sequences(input_data, output_data, window_size, step):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(0, len(input_data) - window_size, step):\n",
    "        sequences.append(input_data[i:(i + window_size)])\n",
    "        labels.append(output_data[i + window_size])\n",
    "    return np.array(sequences), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29b8e189-7f39-435a-8038-39098b147325",
    "outputId": "58929080-0b31-4030-94cb-1664b8c8733d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select features\n",
    "features = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "labels = df['High'].shift(-1)  # Next day's high price as label\n",
    "\n",
    "# window siez & step 在這!!!\n",
    "X, y = create_sequences(features, labels, window_size=10, step=15)\n",
    "\n",
    "print(f'Shape of data X: {X.shape}')\n",
    "print(f'Shape of data y: {y.shape}')\n",
    "\n",
    "# split the hold-out tests\n",
    "ind = np.linspace(0, len(X)-1, num=int(len(X)*0.1), dtype=int) # 10% hold-out\n",
    "x_test = X[ind]\n",
    "y_test = y[ind]\n",
    "all_ind = np.arange(len(X))\n",
    "remains_ind = np.delete(all_ind, ind)\n",
    "\n",
    "X = X[remains_ind]\n",
    "y = y[remains_ind]\n",
    "\n",
    "# shuffle dataset\n",
    "ind = np.random.permutation(len(X))\n",
    "X = X[ind]\n",
    "y = y[ind]\n",
    "split_point = int(X.shape[0]*0.8)\n",
    "\n",
    "x_train = X[:split_point]\n",
    "y_train = y[:split_point]\n",
    "x_val = X[split_point:]\n",
    "y_val = y[split_point:]\n",
    "\n",
    "print(f'Shape of data x_train: {x_train.shape}')\n",
    "print(f'Shape of data y_train: {y_train.shape}')\n",
    "print(f'Shape of data x_val: {x_val.shape}')\n",
    "print(f'Shape of data y_val: {y_val.shape}')\n",
    "print(f'Shape of data x_test: {x_test.shape}')\n",
    "print(f'Shape of data y_test: {y_test.shape}')\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "x_val = torch.from_numpy(x_val).float()\n",
    "y_val = torch.from_numpy(y_val).float()\n",
    "\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Number of samples in training and validation are {len(train_loader.dataset)} and {len(val_loader.dataset)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "8ffc26b9-6044-41e9-93e2-7dc6250dbd27"
   },
   "source": [
    "## B. Defining Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "77975746-a7a7-4676-9527-57674cd98c0f"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "cbb8b5b0-0ec0-406c-a42e-048aa00e05aa"
   },
   "source": [
    "## C. Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3602ae7d-4034-4c49-b221-0c12a5824b18",
    "outputId": "02db6dfa-c683-492c-a5da-4bee3e890d79"
   },
   "outputs": [],
   "source": [
    "# Check your GPU status.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "30032a66ac7348a481a49b12d8c2e2d2",
      "bf90f6630aa24c7894b5e1e9ee4be00a",
      "078bdb87ec7042228759927e0391a49f",
      "ccd3a9372e38452087ba46f36d11c273",
      "ce4018e5970b43e79400f080852a0653",
      "ff798a8807f84f2bbda02f01f10d2239",
      "f0ba57b76fd143fca9e5653d28cb82b6",
      "635fd2573ae44006b9407ffaa3ad2e69",
      "9fa40f438de244a4b88daca46a53338b",
      "c7bce89efc9f4d9dbe8fa329c0e75730",
      "f4205f89e17c40ab930dbd37b8a34536"
     ]
    },
    "id": "f73a5c35-c15d-49bb-8a33-a7f017159499",
    "outputId": "17e4ad08-e924-4b1e-ac73-7a3613445d12"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "model = LSTMModel(input_dim=5, hidden_dim=500, num_layers=2, output_dim=1).cuda()\n",
    "print(model)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = model(features).squeeze(-1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Learning rate update\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features = features.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(features).squeeze(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # Checkpoint\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train loss: {avg_train_loss:.4f}, Val loss: {avg_val_loss:.4f}, Best Val loss: {best_val_loss:.4f}')\n",
    "\n",
    "    # Store performance\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "id": "a7984c6e-6652-4160-b572-07d48bc93a3f"
   },
   "source": [
    "#### Visualizing the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "5559d850-1fb5-4b04-b6ca-60c5b309f34e",
    "outputId": "50b263a9-20ad-4071-d904-8eff08615614"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Val'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "89c7e51b-8ab6-4aa2-877d-39b6daf55c20"
   },
   "source": [
    "## D. Evaluating Your Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "4bcf8580-42ee-4ee7-ad15-9f080cc57a33"
   },
   "outputs": [],
   "source": [
    "# Load the trained weights\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "pred_value = []\n",
    "actual_value = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features = features.cuda()\n",
    "        outputs = model(features).squeeze(-1)\n",
    "        pred_value.append(outputs.cpu())\n",
    "        actual_value.append(labels)\n",
    "\n",
    "pred_value = torch.cat(pred_value)\n",
    "actual_value = torch.cat(actual_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "dde4e0a5-32be-4db3-95fb-4fad8926ce9b",
    "outputId": "cf6ee026-4384-40cb-deda-e487c6891478"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(pred_value[:])\n",
    "plt.plot(actual_value[:])\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price')\n",
    "plt.legend(['Pred', 'Actual'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "Y-5p0405eHzb"
   },
   "source": [
    "# 以下是跟作業相關的程式碼:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "dHAzY0rP3Vxn"
   },
   "outputs": [],
   "source": [
    "# 將模型訓練封裝成函數以利重複使用\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def train_and_evaluate(window_size, step, scaling='none'):\n",
    "    raw_features = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    labels = df['High'].shift(-1).values  # 預測下一天的 High\n",
    "\n",
    "    # 處理 normalization\n",
    "    if scaling == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "        features = scaler.fit_transform(raw_features)\n",
    "    elif scaling == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        features = scaler.fit_transform(raw_features)\n",
    "    else:  # no normalization\n",
    "        features = raw_features.values\n",
    "\n",
    "    # 後續流程照原本進行\n",
    "    X, y = create_sequences(features, labels, window_size=window_size, step=step)\n",
    "\n",
    "    X = X.astype(np.float32)\n",
    "    y = y.astype(np.float32)\n",
    "\n",
    "    # drop NA\n",
    "    mask = ~np.isnan(y)\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    # 分出 test\n",
    "    ind = np.linspace(0, len(X)-1, num=int(len(X)*0.1), dtype=int)\n",
    "    x_test = X[ind]\n",
    "    y_test = y[ind]\n",
    "    remains_ind = np.delete(np.arange(len(X)), ind)\n",
    "\n",
    "    X = X[remains_ind]\n",
    "    y = y[remains_ind]\n",
    "\n",
    "    # shuffle + split train/val\n",
    "    ind = np.random.permutation(len(X))\n",
    "    X = X[ind]\n",
    "    y = y[ind]\n",
    "    split_point = int(X.shape[0]*0.8)\n",
    "    x_train = X[:split_point]\n",
    "    y_train = y[:split_point]\n",
    "    x_val = X[split_point:]\n",
    "    y_val = y[split_point:]\n",
    "\n",
    "    # tensor 化\n",
    "    x_train = torch.from_numpy(x_train).float().cuda()\n",
    "    y_train = torch.from_numpy(y_train).float().cuda()\n",
    "    x_val = torch.from_numpy(x_val).float().cuda()\n",
    "    y_val = torch.from_numpy(y_val).float().cuda()\n",
    "    x_test = torch.from_numpy(x_test).float().cuda()\n",
    "    y_test = torch.from_numpy(y_test).float().cuda()\n",
    "\n",
    "    # dataloader\n",
    "    train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(x_val, y_val), batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=32, shuffle=False)\n",
    "\n",
    "    # 模型與訓練設定\n",
    "    model = LSTMModel(input_dim=5, hidden_dim=500, num_layers=2, output_dim=1).cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for features, labels in train_loader:\n",
    "            outputs = model(features).squeeze(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "\n",
    "        # 驗證\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                outputs = model(features).squeeze(-1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "\n",
    "    # 測試 MSE\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            outputs = model(features).squeeze(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "    return best_val_loss, avg_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "UycnfmrqAaHi"
   },
   "outputs": [],
   "source": [
    "# 將模型訓練封裝成函數以利重複使用\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def train_and_evaluate_noVol(window_size, step, scaling='none'):\n",
    "    raw_features = df[['Open', 'High', 'Low', 'Close']]\n",
    "    labels = df['High'].shift(-1).values  # 預測下一天的 High\n",
    "\n",
    "    # 處理 normalization\n",
    "    if scaling == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "        features = scaler.fit_transform(raw_features)\n",
    "    elif scaling == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        features = scaler.fit_transform(raw_features)\n",
    "    else:  # no normalization\n",
    "        features = raw_features.values\n",
    "\n",
    "    # 後續流程照原本進行\n",
    "    X, y = create_sequences(features, labels, window_size=window_size, step=step)\n",
    "\n",
    "    X = X.astype(np.float32)\n",
    "    y = y.astype(np.float32)\n",
    "\n",
    "    # drop NA\n",
    "    mask = ~np.isnan(y)\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    # 分出 test\n",
    "    ind = np.linspace(0, len(X)-1, num=int(len(X)*0.1), dtype=int)\n",
    "    x_test = X[ind]\n",
    "    y_test = y[ind]\n",
    "    remains_ind = np.delete(np.arange(len(X)), ind)\n",
    "\n",
    "    X = X[remains_ind]\n",
    "    y = y[remains_ind]\n",
    "\n",
    "    # shuffle + split train/val\n",
    "    ind = np.random.permutation(len(X))\n",
    "    X = X[ind]\n",
    "    y = y[ind]\n",
    "    split_point = int(X.shape[0]*0.8)\n",
    "    x_train = X[:split_point]\n",
    "    y_train = y[:split_point]\n",
    "    x_val = X[split_point:]\n",
    "    y_val = y[split_point:]\n",
    "\n",
    "    # tensor 化\n",
    "    x_train = torch.from_numpy(x_train).float().cuda()\n",
    "    y_train = torch.from_numpy(y_train).float().cuda()\n",
    "    x_val = torch.from_numpy(x_val).float().cuda()\n",
    "    y_val = torch.from_numpy(y_val).float().cuda()\n",
    "    x_test = torch.from_numpy(x_test).float().cuda()\n",
    "    y_test = torch.from_numpy(y_test).float().cuda()\n",
    "\n",
    "    # dataloader\n",
    "    train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(x_val, y_val), batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=32, shuffle=False)\n",
    "\n",
    "    # 模型與訓練設定\n",
    "    model = LSTMModel(input_dim=4, hidden_dim=500, num_layers=2, output_dim=1).cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for features, labels in train_loader:\n",
    "            outputs = model(features).squeeze(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "\n",
    "        # 驗證\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                outputs = model(features).squeeze(-1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "\n",
    "    # 測試 MSE\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            outputs = model(features).squeeze(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "    return best_val_loss, avg_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "WBpnfo6C4Bfq"
   },
   "source": [
    "第三題: 加上 volume, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "id": "4eoaiCwv3W-E"
   },
   "outputs": [],
   "source": [
    "# 測試不同 window size & step 組合\n",
    "window_step_combos = [(5, 1), (1, 5), (15, 10), (10, 10), (10, 15) ,(30, 20), (20, 30)]\n",
    "scaling_methods = ['none', 'minmax', 'standard']\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILuVXof83Z5v",
    "outputId": "2fa9a600-50e3-466a-ec48-eb7b4f624682"
   },
   "outputs": [],
   "source": [
    "print(\"未加上Volume\")\n",
    "for scaling in scaling_methods:\n",
    "    print(f\"\\n=== Scaling method: {scaling.upper()} ===\")\n",
    "    for ws, st in window_step_combos:\n",
    "        print(f\"Training for window_size={ws}, step={st}\")\n",
    "        val_loss, test_loss = train_and_evaluate_noVol(ws, st, scaling=scaling)\n",
    "        results.append((scaling, ws, st, val_loss, test_loss))\n",
    "        print(f\"--> Val Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"加上Volume\")\n",
    "for scaling in scaling_methods:\n",
    "    print(f\"\\n=== Scaling method: {scaling.upper()} ===\")\n",
    "    for ws, st in window_step_combos:\n",
    "        print(f\"Training for window_size={ws}, step={st}\")\n",
    "        val_loss, test_loss = train_and_evaluate(ws, st, scaling=scaling)\n",
    "        results.append((scaling, ws, st, val_loss, test_loss))\n",
    "        print(f\"--> Val Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UqztsOQu8RVp",
    "outputId": "d9261196-4718-4f6e-d5f2-55280d076947"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 將結果轉成 DataFrame 表格\n",
    "results_df = pd.DataFrame(results, columns=['Scaling', 'Window Size', 'Step Size', 'Val MSE', 'Test MSE'])\n",
    "\n",
    "# 以 Excel 樣式格式化顯示，但不加高亮或標記\n",
    "results_df.style.set_caption(\"All Results Comparison\") \\\n",
    "                .format({'Val MSE': '{:.4f}', 'Test MSE': '{:.4f}'}) \\\n",
    "                .set_table_styles([{\n",
    "                    'selector': 'th',\n",
    "                    'props': [('background-color', '#f0f0f0'), ('font-weight', 'bold')]\n",
    "                }])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
